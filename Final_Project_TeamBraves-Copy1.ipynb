{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aae3b994",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in c:\\programdata\\anaconda3\\lib\\site-packages (1.6.0)\n",
      "Requirement already satisfied: scipy in c:\\programdata\\anaconda3\\lib\\site-packages (from xgboost) (1.6.2)\n",
      "Requirement already satisfied: numpy in c:\\programdata\\anaconda3\\lib\\site-packages (from xgboost) (1.20.1)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "!pip install xgboost\n",
    "import string\n",
    "import contractions\n",
    "from nltk import word_tokenize          \n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a289068",
   "metadata": {},
   "source": [
    "# Reading data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fbd2ad08",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('TA_Training_Set.csv', error_bad_lines=False, engine='python') \n",
    "test_data= pd.read_csv('TA_Test_Set.csv', error_bad_lines=False, engine='python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33ee8ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data.sample(n=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71f8261d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "      <th>Topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>53871</th>\n",
       "      <td>Here you go.\\nTwitter: https://twitter.com/MDF...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565102</th>\n",
       "      <td>It's okay because they're both good looking.</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24065</th>\n",
       "      <td>Earthmelon sounds like a really juicy mushroom...</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798821</th>\n",
       "      <td>You are doing God's work</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225268</th>\n",
       "      <td>Her ultra wealthy rich super genius husband?</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Comment  Topic\n",
       "53871   Here you go.\\nTwitter: https://twitter.com/MDF...      2\n",
       "565102       It's okay because they're both good looking.     30\n",
       "24065   Earthmelon sounds like a really juicy mushroom...     18\n",
       "798821                           You are doing God's work     29\n",
       "225268       Her ultra wealthy rich super genius husband?     30"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "832f1f91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I bought a month and a half out on a stock tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Parity used to be the justification, but that ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Yeah cartel. Legolas is gonna shoot your ass d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I do think he’s TA, but there’s one thing with...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Were trying, let you know if anything works</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>As I migraine sufferer I can tell you coffee i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>If she was a drink she'd be room temperature t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>I live on campus here. And was there when it h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>bro nobody likes that shit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>I got that, but logic would suggest to name th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Comment\n",
       "0      I bought a month and a half out on a stock tha...\n",
       "1      Parity used to be the justification, but that ...\n",
       "2      Yeah cartel. Legolas is gonna shoot your ass d...\n",
       "3      I do think he’s TA, but there’s one thing with...\n",
       "4            Were trying, let you know if anything works\n",
       "...                                                  ...\n",
       "99995  As I migraine sufferer I can tell you coffee i...\n",
       "99996  If she was a drink she'd be room temperature t...\n",
       "99997  I live on campus here. And was there when it h...\n",
       "99998                         bro nobody likes that shit\n",
       "99999  I got that, but logic would suggest to name th...\n",
       "\n",
       "[100000 rows x 1 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c70af27c",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "79dc50bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "      <th>Topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>53871</th>\n",
       "      <td>Here you go.\\nTwitter: https://twitter.com/MDF...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565102</th>\n",
       "      <td>It's okay because they're both good looking.</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24065</th>\n",
       "      <td>Earthmelon sounds like a really juicy mushroom...</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798821</th>\n",
       "      <td>You are doing God's work</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225268</th>\n",
       "      <td>Her ultra wealthy rich super genius husband?</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>761751</th>\n",
       "      <td>Ah, english is not my first language, my brows...</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403292</th>\n",
       "      <td>You mean crying about other people being close...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>856433</th>\n",
       "      <td>So my theory is that King Crimson is The Boss'...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>783972</th>\n",
       "      <td>Obama is a biracial man who identifies as blac...</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>895566</th>\n",
       "      <td>It's not even close to the same, but I've been...</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>82421 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Comment  Topic\n",
       "53871   Here you go.\\nTwitter: https://twitter.com/MDF...      2\n",
       "565102       It's okay because they're both good looking.     30\n",
       "24065   Earthmelon sounds like a really juicy mushroom...     18\n",
       "798821                           You are doing God's work     29\n",
       "225268       Her ultra wealthy rich super genius husband?     30\n",
       "...                                                   ...    ...\n",
       "761751  Ah, english is not my first language, my brows...     17\n",
       "403292  You mean crying about other people being close...      3\n",
       "856433  So my theory is that King Crimson is The Boss'...      2\n",
       "783972  Obama is a biracial man who identifies as blac...     28\n",
       "895566  It's not even close to the same, but I've been...     20\n",
       "\n",
       "[82421 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "data=data.loc[data['Comment'].str.contains(r'[^\\x00-\\x7F]+') == False]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b342b9ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I bought a month and a half out on a stock tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Parity used to be the justification, but that ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Yeah cartel. Legolas is gonna shoot your ass d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I do think he’s TA, but there’s one thing with...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Were trying, let you know if anything works</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>As I migraine sufferer I can tell you coffee i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>If she was a drink she'd be room temperature t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>I live on campus here. And was there when it h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>bro nobody likes that shit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>I got that, but logic would suggest to name th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Comment\n",
       "0      I bought a month and a half out on a stock tha...\n",
       "1      Parity used to be the justification, but that ...\n",
       "2      Yeah cartel. Legolas is gonna shoot your ass d...\n",
       "3      I do think he’s TA, but there’s one thing with...\n",
       "4            Were trying, let you know if anything works\n",
       "...                                                  ...\n",
       "99995  As I migraine sufferer I can tell you coffee i...\n",
       "99996  If she was a drink she'd be room temperature t...\n",
       "99997  I live on campus here. And was there when it h...\n",
       "99998                         bro nobody likes that shit\n",
       "99999  I got that, but logic would suggest to name th...\n",
       "\n",
       "[100000 rows x 1 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b8a7655",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\scherukuri1\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "stop = stopwords.words('english')\n",
    "\n",
    "data['x_without_stopwords'] = data['Comment'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))\n",
    "test_data['x_without_stopwords'] = test_data['Comment'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d5a80764",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "      <th>x_without_stopwords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I bought a month and a half out on a stock tha...</td>\n",
       "      <td>I bought month half stock almost option volume...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Parity used to be the justification, but that ...</td>\n",
       "      <td>Parity used justification, days free agency. I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Yeah cartel. Legolas is gonna shoot your ass d...</td>\n",
       "      <td>Yeah cartel. Legolas gonna shoot ass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I do think he’s TA, but there’s one thing with...</td>\n",
       "      <td>I think he’s TA, there’s one thing you’re sayi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Were trying, let you know if anything works</td>\n",
       "      <td>Were trying, let know anything works</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>As I migraine sufferer I can tell you coffee i...</td>\n",
       "      <td>As I migraine sufferer I tell coffee catalyst ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>If she was a drink she'd be room temperature t...</td>\n",
       "      <td>If drink she'd room temperature tap water</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>I live on campus here. And was there when it h...</td>\n",
       "      <td>I live campus here. And happened. Super fucked</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>bro nobody likes that shit</td>\n",
       "      <td>bro nobody likes shit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>I got that, but logic would suggest to name th...</td>\n",
       "      <td>I got that, logic would suggest name son 'Shot...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Comment  \\\n",
       "0      I bought a month and a half out on a stock tha...   \n",
       "1      Parity used to be the justification, but that ...   \n",
       "2      Yeah cartel. Legolas is gonna shoot your ass d...   \n",
       "3      I do think he’s TA, but there’s one thing with...   \n",
       "4            Were trying, let you know if anything works   \n",
       "...                                                  ...   \n",
       "99995  As I migraine sufferer I can tell you coffee i...   \n",
       "99996  If she was a drink she'd be room temperature t...   \n",
       "99997  I live on campus here. And was there when it h...   \n",
       "99998                         bro nobody likes that shit   \n",
       "99999  I got that, but logic would suggest to name th...   \n",
       "\n",
       "                                     x_without_stopwords  \n",
       "0      I bought month half stock almost option volume...  \n",
       "1      Parity used justification, days free agency. I...  \n",
       "2                   Yeah cartel. Legolas gonna shoot ass  \n",
       "3      I think he’s TA, there’s one thing you’re sayi...  \n",
       "4                   Were trying, let know anything works  \n",
       "...                                                  ...  \n",
       "99995  As I migraine sufferer I tell coffee catalyst ...  \n",
       "99996          If drink she'd room temperature tap water  \n",
       "99997     I live campus here. And happened. Super fucked  \n",
       "99998                              bro nobody likes shit  \n",
       "99999  I got that, logic would suggest name son 'Shot...  \n",
       "\n",
       "[100000 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f6a1e8d0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-cee0bf171ffb>:4: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  data[\"x_without_stopwords\"] = data[\"x_without_stopwords\"].str.replace('\\d+', '')\n",
      "<ipython-input-10-cee0bf171ffb>:6: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  test_data[\"x_without_stopwords\"] = test_data[\"x_without_stopwords\"].str.replace('\\d+', '')\n",
      "<ipython-input-10-cee0bf171ffb>:3: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will*not* be treated as literal strings when regex=True.\n",
      "  data[\"x_without_stopwords\"] = data[\"x_without_stopwords\"].str.replace(i,'')\n",
      "<ipython-input-10-cee0bf171ffb>:5: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will*not* be treated as literal strings when regex=True.\n",
      "  test_data[\"x_without_stopwords\"] = test_data[\"x_without_stopwords\"].str.replace(i,'')\n"
     ]
    }
   ],
   "source": [
    "symbols = \"!\\\"#$%&()*+-./:;<=>?@[\\]^_`{|}~\\nÄô\"\n",
    "for i in symbols:\n",
    "    data[\"x_without_stopwords\"] = data[\"x_without_stopwords\"].str.replace(i,'')\n",
    "    data[\"x_without_stopwords\"] = data[\"x_without_stopwords\"].str.replace('\\d+', '')\n",
    "    test_data[\"x_without_stopwords\"] = test_data[\"x_without_stopwords\"].str.replace(i,'')\n",
    "    test_data[\"x_without_stopwords\"] = test_data[\"x_without_stopwords\"].str.replace('\\d+', '')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b60b8457",
   "metadata": {},
   "source": [
    "# Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3b9d4d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data['x_without_stopwords'], \n",
    "    data['Topic'], \n",
    "    random_state=11, \n",
    "    test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d655fa0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(74178,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "32c2e15e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "618254    Idk, Brienne riding horse  pages AFfC pretty c...\n",
       "195318                       We watch career great interest\n",
       "417217    Yeah damn rockets fault though delivering nuke...\n",
       "376174           Don't forget watch league gets like  views\n",
       "Name: x_without_stopwords, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "54ec1442",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    I bought month half stock almost option volume...\n",
       "1    Parity used justification, days free agency It...\n",
       "2                  Yeah cartel Legolas gonna shoot ass\n",
       "3    I think he’s TA, there’s one thing you’re sayi...\n",
       "4                 Were trying, let know anything works\n",
       "Name: x_without_stopwords, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_prof = test_data[\"x_without_stopwords\"]\n",
    "test_data_prof.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "73ca8341",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "      <th>x_without_stopwords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I bought a month and a half out on a stock tha...</td>\n",
       "      <td>I bought month half stock almost option volume...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Parity used to be the justification, but that ...</td>\n",
       "      <td>Parity used justification, days free agency It...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Yeah cartel. Legolas is gonna shoot your ass d...</td>\n",
       "      <td>Yeah cartel Legolas gonna shoot ass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I do think he’s TA, but there’s one thing with...</td>\n",
       "      <td>I think he’s TA, there’s one thing you’re sayi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Were trying, let you know if anything works</td>\n",
       "      <td>Were trying, let know anything works</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Comment  \\\n",
       "0  I bought a month and a half out on a stock tha...   \n",
       "1  Parity used to be the justification, but that ...   \n",
       "2  Yeah cartel. Legolas is gonna shoot your ass d...   \n",
       "3  I do think he’s TA, but there’s one thing with...   \n",
       "4        Were trying, let you know if anything works   \n",
       "\n",
       "                                 x_without_stopwords  \n",
       "0  I bought month half stock almost option volume...  \n",
       "1  Parity used justification, days free agency It...  \n",
       "2                Yeah cartel Legolas gonna shoot ass  \n",
       "3  I think he’s TA, there’s one thing you’re sayi...  \n",
       "4               Were trying, let know anything works  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7cafc40",
   "metadata": {},
   "source": [
    "# Lemmatizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "be7dee05",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LemmaTokenizer(object):\n",
    "    def __init__(self):\n",
    "        self.wnl = WordNetLemmatizer()\n",
    "    def __call__(self, text):\n",
    "        text = contractions.fix(text)\n",
    "        return [self.wnl.lemmatize(t) for t in word_tokenize(text) if t not in string.punctuation]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "724f9037",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2e876830",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\scherukuri1\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\scherukuri1\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import nltk\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "\n",
    "xg_clf = Pipeline([\n",
    "    ('vect', CountVectorizer(tokenizer=LemmaTokenizer(),stop_words='english')), # returns matrix of token counts\n",
    "    ('tfidf', TfidfTransformer()), # transform a count matrix to a normalized tf or tf-idf representation\n",
    "    ('clf', LogisticRegression( penalty='l2', tol=0.0001, C=1.0, fit_intercept=True, intercept_scaling=1,\n",
    "                               class_weight=None, random_state=None, solver='lbfgs', max_iter=1000, multi_class='auto',\n",
    "                               verbose=0, warm_start=False, n_jobs=None, l1_ratio=None)\n",
    "    ),\n",
    "])\n",
    "\n",
    "xg_clf_rf = Pipeline([\n",
    "    ('vect', CountVectorizer(tokenizer=LemmaTokenizer(),stop_words='english')), # returns matrix of token counts\n",
    "    ('tfidf', TfidfTransformer()), # transform a count matrix to a normalized tf or tf-idf representation\n",
    "    ('clf', RandomForestClassifier(n_estimators=400)\n",
    "    ),\n",
    "])\n",
    "\n",
    "xg_clf_svm= Pipeline([\n",
    "    ('vect', CountVectorizer(tokenizer=LemmaTokenizer(),stop_words='english')), # returns matrix of token counts\n",
    "    ('tfidf', TfidfTransformer()), # transform a count matrix to a normalized tf or tf-idf representation\n",
    "    ('clf', svm.SVC(kernel='sigmoid')\n",
    "    ),\n",
    "])\n",
    "\n",
    "xg_clf_dt= Pipeline([\n",
    "    ('vect', CountVectorizer(tokenizer=LemmaTokenizer(),stop_words='english')), # returns matrix of token counts\n",
    "    ('tfidf', TfidfTransformer()), # transform a count matrix to a normalized tf or tf-idf representation\n",
    "    ('clf', DecisionTreeClassifier()\n",
    "    ),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a542c68b",
   "metadata": {},
   "source": [
    "# LOGISTIC REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a6d96326",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ha', 'le', 'u', 'wa'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vect',\n",
       "                 CountVectorizer(stop_words='english',\n",
       "                                 tokenizer=<__main__.LemmaTokenizer object at 0x00000256CD7C6CA0>)),\n",
       "                ('tfidf', TfidfTransformer()),\n",
       "                ('clf', LogisticRegression(max_iter=1000))])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xg_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6bed9be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_lr = xg_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "20428d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_lr_test_data = xg_clf.predict(test_data_prof)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c9bb9280",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_lr_test_data_df=pd.DataFrame(predict_lr_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "10f7f025",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "      <th>x_without_stopwords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I bought a month and a half out on a stock tha...</td>\n",
       "      <td>I bought month half stock almost option volume...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Parity used to be the justification, but that ...</td>\n",
       "      <td>Parity used justification, days free agency It...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Yeah cartel. Legolas is gonna shoot your ass d...</td>\n",
       "      <td>Yeah cartel Legolas gonna shoot ass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I do think he’s TA, but there’s one thing with...</td>\n",
       "      <td>I think he’s TA, there’s one thing you’re sayi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Were trying, let you know if anything works</td>\n",
       "      <td>Were trying, let know anything works</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>As I migraine sufferer I can tell you coffee i...</td>\n",
       "      <td>As I migraine sufferer I tell coffee catalyst ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>If she was a drink she'd be room temperature t...</td>\n",
       "      <td>If drink she'd room temperature tap water</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>I live on campus here. And was there when it h...</td>\n",
       "      <td>I live campus here And happened Super fucked</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>bro nobody likes that shit</td>\n",
       "      <td>bro nobody likes shit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>I got that, but logic would suggest to name th...</td>\n",
       "      <td>I got that, logic would suggest name son 'Shot...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Comment  \\\n",
       "0      I bought a month and a half out on a stock tha...   \n",
       "1      Parity used to be the justification, but that ...   \n",
       "2      Yeah cartel. Legolas is gonna shoot your ass d...   \n",
       "3      I do think he’s TA, but there’s one thing with...   \n",
       "4            Were trying, let you know if anything works   \n",
       "...                                                  ...   \n",
       "99995  As I migraine sufferer I can tell you coffee i...   \n",
       "99996  If she was a drink she'd be room temperature t...   \n",
       "99997  I live on campus here. And was there when it h...   \n",
       "99998                         bro nobody likes that shit   \n",
       "99999  I got that, but logic would suggest to name th...   \n",
       "\n",
       "                                     x_without_stopwords  \n",
       "0      I bought month half stock almost option volume...  \n",
       "1      Parity used justification, days free agency It...  \n",
       "2                    Yeah cartel Legolas gonna shoot ass  \n",
       "3      I think he’s TA, there’s one thing you’re sayi...  \n",
       "4                   Were trying, let know anything works  \n",
       "...                                                  ...  \n",
       "99995  As I migraine sufferer I tell coffee catalyst ...  \n",
       "99996          If drink she'd room temperature tap water  \n",
       "99997       I live campus here And happened Super fucked  \n",
       "99998                              bro nobody likes shit  \n",
       "99999  I got that, logic would suggest name son 'Shot...  \n",
       "\n",
       "[100000 rows x 2 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8610eb22",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_new_df = pd.concat([test_data, predict_lr_test_data_df], axis =1)\n",
    "\n",
    "my_new_df.to_csv(\"Topic_Analysis_Output.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "808c8c1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.4470046705002565\n"
     ]
    }
   ],
   "source": [
    "# Accuracy\n",
    "print('Accuracy =', np.mean(predict_lr == y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "81f98d2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1037   11   32 ...   28   15   14]\n",
      " [  11  891   33 ...   44   31   13]\n",
      " [  26   54  334 ...   58   36   27]\n",
      " ...\n",
      " [  15   42   42 ...  639   42   39]\n",
      " [  11   42   28 ...   18 1238   13]\n",
      " [  16   21   31 ...   44   27  659]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.65      0.60      0.62      1728\n",
      "           2       0.35      0.43      0.39      2052\n",
      "           3       0.21      0.18      0.19      1888\n",
      "           4       0.36      0.36      0.36      1913\n",
      "           5       0.50      0.48      0.49      1797\n",
      "           6       0.69      0.83      0.75      1705\n",
      "           7       0.61      0.61      0.61      1803\n",
      "           8       0.23      0.11      0.15        27\n",
      "           9       0.40      0.50      0.44      1925\n",
      "          10       0.37      0.38      0.38      1929\n",
      "          11       0.70      0.63      0.66      1969\n",
      "          12       0.35      0.30      0.32      1929\n",
      "          13       0.57      0.57      0.57      1860\n",
      "          14       0.44      0.45      0.44      1854\n",
      "          15       0.42      0.45      0.44      1953\n",
      "          16       0.57      0.42      0.48      2040\n",
      "          17       0.35      0.31      0.33      1790\n",
      "          18       0.20      0.17      0.18      1898\n",
      "          19       0.43      0.34      0.38      1817\n",
      "          20       0.38      0.39      0.38      1935\n",
      "          21       0.48      0.70      0.57      2066\n",
      "          22       0.57      0.59      0.58      1846\n",
      "          23       0.72      0.69      0.70      2058\n",
      "          24       0.54      0.53      0.53      1815\n",
      "          25       0.31      0.27      0.29      1976\n",
      "          26       0.41      0.36      0.39      1967\n",
      "          27       0.65      0.67      0.66      1933\n",
      "          28       0.35      0.38      0.36      1876\n",
      "          29       0.55      0.49      0.52      1947\n",
      "          30       0.25      0.19      0.22      1995\n",
      "          31       0.50      0.48      0.49      1877\n",
      "          32       0.42      0.60      0.49      1644\n",
      "          33       0.65      0.63      0.64      2019\n",
      "          34       0.21      0.21      0.21      1787\n",
      "          35       0.30      0.33      0.31      1985\n",
      "          36       0.32      0.30      0.31      1778\n",
      "          37       0.34      0.36      0.35      1823\n",
      "          38       0.32      0.32      0.32      1969\n",
      "          39       0.56      0.63      0.59      1965\n",
      "          40       0.37      0.34      0.35      1944\n",
      "\n",
      "    accuracy                           0.45     74082\n",
      "   macro avg       0.44      0.44      0.44     74082\n",
      "weighted avg       0.45      0.45      0.44     74082\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, predict_lr))\n",
    "print(classification_report(\n",
    "    y_test, \n",
    "    predict_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6e2a4a57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training accuracy is :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.71      0.66      0.68     15680\n",
      "           2       0.44      0.54      0.49     17987\n",
      "           3       0.35      0.29      0.32     16698\n",
      "           4       0.48      0.48      0.48     17684\n",
      "           5       0.59      0.55      0.57     16556\n",
      "           6       0.71      0.85      0.78     15155\n",
      "           7       0.67      0.66      0.66     16614\n",
      "           8       0.51      0.14      0.21       361\n",
      "           9       0.47      0.60      0.53     17144\n",
      "          10       0.47      0.46      0.47     17330\n",
      "          11       0.74      0.68      0.70     17287\n",
      "          12       0.50      0.45      0.47     17680\n",
      "          13       0.63      0.63      0.63     16801\n",
      "          14       0.56      0.59      0.57     17201\n",
      "          15       0.50      0.57      0.54     17061\n",
      "          16       0.64      0.49      0.55     18313\n",
      "          17       0.51      0.43      0.47     16806\n",
      "          18       0.35      0.30      0.33     17218\n",
      "          19       0.59      0.47      0.52     16674\n",
      "          20       0.49      0.47      0.48     17846\n",
      "          21       0.50      0.75      0.60     17771\n",
      "          22       0.66      0.66      0.66     17434\n",
      "          23       0.76      0.73      0.75     18687\n",
      "          24       0.60      0.60      0.60     16291\n",
      "          25       0.44      0.38      0.41     17772\n",
      "          26       0.49      0.45      0.47     17403\n",
      "          27       0.71      0.71      0.71     17469\n",
      "          28       0.48      0.50      0.49     16992\n",
      "          29       0.62      0.57      0.59     17318\n",
      "          30       0.40      0.31      0.35     17416\n",
      "          31       0.57      0.56      0.57     16738\n",
      "          32       0.48      0.66      0.55     14782\n",
      "          33       0.70      0.70      0.70     17682\n",
      "          34       0.31      0.31      0.31     16202\n",
      "          35       0.42      0.47      0.45     17637\n",
      "          36       0.42      0.40      0.41     16279\n",
      "          37       0.42      0.43      0.42     16290\n",
      "          38       0.44      0.44      0.44     17937\n",
      "          39       0.60      0.69      0.64     17333\n",
      "          40       0.48      0.46      0.47     17208\n",
      "\n",
      "    accuracy                           0.54    666737\n",
      "   macro avg       0.54      0.53      0.53    666737\n",
      "weighted avg       0.54      0.54      0.53    666737\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"The training accuracy is :\")\n",
    "print(classification_report(\n",
    "    y_train, \n",
    "    xg_clf.predict(X_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "152e7e4f",
   "metadata": {},
   "source": [
    "# RANDOM FOREST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c86c8f60",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ha', 'le', 'u', 'wa'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.3214848962756278\n",
      "[[103   3   7 ...   4   2   4]\n",
      " [  1  64   3 ...   2   2   0]\n",
      " [  1   9  24 ...   3   8   6]\n",
      " ...\n",
      " [  1   6   1 ...  40   1   7]\n",
      " [  1   8   4 ...   4  96   2]\n",
      " [  1   0   1 ...   3   1  44]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.66      0.50      0.57       204\n",
      "           2       0.27      0.27      0.27       233\n",
      "           3       0.16      0.11      0.13       226\n",
      "           4       0.18      0.15      0.16       228\n",
      "           5       0.33      0.34      0.34       193\n",
      "           6       0.43      0.74      0.55       165\n",
      "           7       0.54      0.52      0.53       229\n",
      "           8       0.00      0.00      0.00         1\n",
      "           9       0.31      0.39      0.34       220\n",
      "          10       0.35      0.30      0.32       204\n",
      "          11       0.50      0.47      0.48       205\n",
      "          12       0.23      0.15      0.18       201\n",
      "          13       0.38      0.40      0.39       220\n",
      "          14       0.35      0.39      0.37       211\n",
      "          15       0.32      0.38      0.35       201\n",
      "          16       0.41      0.36      0.39       231\n",
      "          17       0.30      0.22      0.25       208\n",
      "          18       0.12      0.13      0.13       221\n",
      "          19       0.29      0.18      0.22       195\n",
      "          20       0.24      0.26      0.25       223\n",
      "          21       0.35      0.57      0.43       210\n",
      "          22       0.39      0.43      0.41       210\n",
      "          23       0.48      0.41      0.44       234\n",
      "          24       0.48      0.42      0.45       234\n",
      "          25       0.24      0.26      0.25       231\n",
      "          26       0.29      0.27      0.28       226\n",
      "          27       0.53      0.47      0.50       234\n",
      "          28       0.22      0.30      0.25       179\n",
      "          29       0.31      0.24      0.27       219\n",
      "          30       0.12      0.09      0.10       199\n",
      "          31       0.39      0.45      0.42       212\n",
      "          32       0.31      0.41      0.35       162\n",
      "          33       0.45      0.50      0.47       211\n",
      "          34       0.08      0.15      0.10       169\n",
      "          35       0.21      0.17      0.19       226\n",
      "          36       0.23      0.18      0.20       195\n",
      "          37       0.21      0.21      0.21       196\n",
      "          38       0.24      0.17      0.20       234\n",
      "          39       0.39      0.43      0.41       224\n",
      "          40       0.25      0.20      0.22       219\n",
      "\n",
      "    accuracy                           0.32      8243\n",
      "   macro avg       0.31      0.31      0.31      8243\n",
      "weighted avg       0.32      0.32      0.32      8243\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xg_clf_rf.fit(X_train, y_train)\n",
    "\n",
    "predict_rf = xg_clf_rf.predict(X_test)\n",
    "\n",
    "# Accuracy\n",
    "print('Accuracy =', np.mean(predict_rf == y_test))\n",
    "\n",
    "print(confusion_matrix(y_test, predict_rf))\n",
    "print(classification_report(\n",
    "    y_test, \n",
    "    predict_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb25b1b",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6a226154",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ha', 'le', 'u', 'wa'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.34720368797767803\n",
      "[[105   0   5 ...   1   2   2]\n",
      " [  0  64  11 ...   5   1   4]\n",
      " [  2  12  53 ...   4   4   2]\n",
      " ...\n",
      " [  1   6   8 ...  55   2   5]\n",
      " [  4  11  10 ...   5  90   2]\n",
      " [  4   1   8 ...   8   1  55]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.64      0.51      0.57       204\n",
      "           2       0.25      0.27      0.26       233\n",
      "           3       0.16      0.23      0.19       226\n",
      "           4       0.23      0.22      0.23       228\n",
      "           5       0.35      0.36      0.35       193\n",
      "           6       0.66      0.75      0.70       165\n",
      "           7       0.59      0.53      0.56       229\n",
      "           8       0.00      0.00      0.00         1\n",
      "           9       0.36      0.41      0.38       220\n",
      "          10       0.33      0.36      0.35       204\n",
      "          11       0.59      0.45      0.51       205\n",
      "          12       0.23      0.21      0.22       201\n",
      "          13       0.45      0.46      0.46       220\n",
      "          14       0.40      0.44      0.42       211\n",
      "          15       0.41      0.42      0.42       201\n",
      "          16       0.44      0.33      0.38       231\n",
      "          17       0.28      0.20      0.23       208\n",
      "          18       0.07      0.14      0.10       221\n",
      "          19       0.37      0.24      0.29       195\n",
      "          20       0.25      0.25      0.25       223\n",
      "          21       0.44      0.61      0.51       210\n",
      "          22       0.52      0.42      0.47       210\n",
      "          23       0.70      0.46      0.55       234\n",
      "          24       0.55      0.40      0.46       234\n",
      "          25       0.28      0.31      0.29       231\n",
      "          26       0.28      0.25      0.27       226\n",
      "          27       0.62      0.48      0.54       234\n",
      "          28       0.25      0.34      0.28       179\n",
      "          29       0.41      0.33      0.37       219\n",
      "          30       0.11      0.14      0.12       199\n",
      "          31       0.44      0.40      0.42       212\n",
      "          32       0.41      0.47      0.44       162\n",
      "          33       0.63      0.47      0.54       211\n",
      "          34       0.08      0.11      0.09       169\n",
      "          35       0.22      0.24      0.23       226\n",
      "          36       0.24      0.23      0.24       195\n",
      "          37       0.24      0.25      0.24       196\n",
      "          38       0.24      0.24      0.24       234\n",
      "          39       0.55      0.40      0.46       224\n",
      "          40       0.33      0.25      0.29       219\n",
      "\n",
      "    accuracy                           0.35      8243\n",
      "   macro avg       0.36      0.34      0.35      8243\n",
      "weighted avg       0.38      0.35      0.36      8243\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "xg_clf_svm.fit(X_train, y_train)\n",
    "\n",
    "predict_svm = xg_clf_svm.predict(X_test)\n",
    "\n",
    "# Accuracy\n",
    "print('Accuracy =', np.mean(predict_svm == y_test))\n",
    "\n",
    "print(confusion_matrix(y_test, predict_svm))\n",
    "print(classification_report(\n",
    "    y_test, \n",
    "    predict_svm))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9624c1ee",
   "metadata": {},
   "source": [
    "# DECISION TREE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "141447c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ha', 'le', 'u', 'wa'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.23923328885114642\n",
      "[[94  3  4 ...  2  4  4]\n",
      " [ 1 53  2 ...  5  3  1]\n",
      " [ 4 10 18 ...  0  5  4]\n",
      " ...\n",
      " [ 3  7  4 ... 38  1  7]\n",
      " [ 2  5  3 ...  4 74  4]\n",
      " [ 1  1  6 ...  6  2 31]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.50      0.46      0.48       204\n",
      "           2       0.24      0.23      0.23       233\n",
      "           3       0.09      0.08      0.09       226\n",
      "           4       0.13      0.11      0.12       228\n",
      "           5       0.26      0.28      0.27       193\n",
      "           6       0.47      0.58      0.51       165\n",
      "           7       0.42      0.37      0.39       229\n",
      "           8       0.00      0.00      0.00         1\n",
      "           9       0.24      0.26      0.25       220\n",
      "          10       0.27      0.24      0.26       204\n",
      "          11       0.33      0.37      0.35       205\n",
      "          12       0.14      0.13      0.14       201\n",
      "          13       0.29      0.24      0.26       220\n",
      "          14       0.26      0.26      0.26       211\n",
      "          15       0.19      0.19      0.19       201\n",
      "          16       0.39      0.36      0.38       231\n",
      "          17       0.20      0.17      0.18       208\n",
      "          18       0.05      0.06      0.06       221\n",
      "          19       0.18      0.18      0.18       195\n",
      "          20       0.22      0.20      0.21       223\n",
      "          21       0.34      0.44      0.38       210\n",
      "          22       0.31      0.32      0.32       210\n",
      "          23       0.30      0.26      0.28       234\n",
      "          24       0.32      0.27      0.29       234\n",
      "          25       0.29      0.26      0.27       231\n",
      "          26       0.17      0.16      0.16       226\n",
      "          27       0.42      0.37      0.40       234\n",
      "          28       0.17      0.20      0.18       179\n",
      "          29       0.18      0.14      0.15       219\n",
      "          30       0.10      0.09      0.09       199\n",
      "          31       0.35      0.31      0.33       212\n",
      "          32       0.20      0.21      0.20       162\n",
      "          33       0.40      0.35      0.37       211\n",
      "          34       0.05      0.15      0.08       169\n",
      "          35       0.11      0.12      0.11       226\n",
      "          36       0.14      0.13      0.13       195\n",
      "          37       0.18      0.18      0.18       196\n",
      "          38       0.17      0.16      0.16       234\n",
      "          39       0.35      0.33      0.34       224\n",
      "          40       0.17      0.14      0.16       219\n",
      "\n",
      "    accuracy                           0.24      8243\n",
      "   macro avg       0.24      0.23      0.24      8243\n",
      "weighted avg       0.25      0.24      0.24      8243\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xg_clf_dt.fit(X_train, y_train)\n",
    "\n",
    "predict_dt = xg_clf_dt.predict(X_test)\n",
    "\n",
    "# Accuracy\n",
    "print('Accuracy =', np.mean(predict_dt == y_test))\n",
    "\n",
    "print(confusion_matrix(y_test, predict_dt))\n",
    "print(classification_report(\n",
    "    y_test, \n",
    "    predict_dt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d0a2d9e",
   "metadata": {},
   "source": [
    "# MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b104e06e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ha', 'le', 'u', 'wa'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "text_tfidf = Pipeline([\n",
    "    ('vect', CountVectorizer(tokenizer=LemmaTokenizer(),stop_words='english')), \n",
    "    ('tfidf', TfidfTransformer()), \n",
    "])\n",
    "\n",
    "text_tfidf.fit(X_train)\n",
    "X_train_tfidf = text_tfidf.transform(X_train)\n",
    "X_test_tfidf = text_tfidf.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4c0392ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='logistic', max_iter=800, random_state=10,\n",
       "              solver='lbfgs')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MLP_clf = MLPClassifier(\n",
    "    max_iter=800, \n",
    "    activation='logistic',\n",
    "    solver='lbfgs',\n",
    "    random_state=10)\n",
    "\n",
    "MLP_clf.fit(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c751c0cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[101   0   8 ...   3   1   2]\n",
      " [  1  59  10 ...   4   2   7]\n",
      " [  6  11  32 ...  10   3   5]\n",
      " ...\n",
      " [  3   1   6 ...  50   2   6]\n",
      " [  4   7   9 ...   3  81   2]\n",
      " [  3   2  10 ...   7   3  41]]\n",
      "Accuracy = 0.2980710906223462\n"
     ]
    }
   ],
   "source": [
    "predict_MLP = MLP_clf.predict(X_test_tfidf)\n",
    "print(confusion_matrix(y_test, predict_MLP))\n",
    "# Accuracy\n",
    "print('Accuracy =', np.mean(predict_MLP == y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e56f8e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
